<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.313">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>chapter-02---probability</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="Chapter 02 - Probability_files/libs/clipboard/clipboard.min.js"></script>
<script src="Chapter 02 - Probability_files/libs/quarto-html/quarto.js"></script>
<script src="Chapter 02 - Probability_files/libs/quarto-html/popper.min.js"></script>
<script src="Chapter 02 - Probability_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="Chapter 02 - Probability_files/libs/quarto-html/anchor.min.js"></script>
<link href="Chapter 02 - Probability_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="Chapter 02 - Probability_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="Chapter 02 - Probability_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="Chapter 02 - Probability_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="Chapter 02 - Probability_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">



<section id="probability-is-not-just-about-the-math" class="level1">
<h1>Probability is not just about the math</h1>
<p>When we speak about probability, we speak about a percentage chance (0%-100%) for something to happen, although we often write the percentage as a decimal number, between 0 and 1. If the probability of an event is 0 then it is the same as saying that <em>you are certain that the event will never happen</em>. If the probability is 1 then <em>you are certain that it <strong>will</strong> happen</em>. Life is full of uncertainty, so we assign a number somewhere between 0 and 1 to describe our state of knowledge of the certainty of an event. The probability that you will get struck by lightning sometime in your life is <span class="math inline">\(p=0.0002\)</span>, or 1 out of 5000. Statistical inference is simply the inference in the presence of uncertainty. We try to make the best decisions we can, given incomplete information.</p>
<p>Pierre-Simon Laplace, who first formalized the mathematics of probability, spoke of an agent with perfect knowledge. This agent, Laplace claimed, would not need probability at all.</p>
<blockquote class="blockquote">
<p><em>We may regard the present state of the universe as the effect of its past and the cause of its future. An intellect which at a certain moment would know all forces that set nature in motion, and all positions of all items of which nature is composed, if this intellect were also vast enough to submit these data to analysis, it would embrace in a single formula the movements of the greatest bodies of the universe and those of the tiniest atom; for such an intellect nothing would be uncertain and the future just like the past would be present before its eyes.</em> <span class="citation" data-cites="laplace1825philosophical">[@laplace1825philosophical]</span></p>
</blockquote>
<p>E.T. Jaynes describes it in much the same way. He says that we label something “random” due to our ignorance of the system not to any intrinsic randomness. He calls this labeling the mind-projection fallacy <span class="citation" data-cites="Jaynes2003">[@Jaynes2003]</span>, where you misattribute the unpredictable behavior of a system as a product of the system itself. A rolled die is following the laws of physics, deterministically, and detailed knowledge of the die, the roll, and the surface should allow you to predict 100% of the time what it will do. We lack that knowledge, thus the behavior becomes unpredictable. We often then attribute that unpredictable behavior as a “random die”, as if it were the die that contains the randomness and not our own state of knowledge.</p>
<p>E.T. Jaynes goes further and lists a number of features any system used to make plausible inference must have<span class="citation" data-cites="Jaynes2003">[@Jaynes2003]</span>. These include</p>
<ol type="1">
<li>We must be consistent with the laws of logic<span class="citation" data-cites="sep-aristotle-logic">[@sep-aristotle-logic]</span>.</li>
<li>If a conclusion can be reasoned out in more than one way then every possible way must yield the same result. In other words, we need to be <em>internally consistent</em>.</li>
<li>We must take into account <em>all</em> of the information provided that is relevant to the question. We can’t arbitrarily ignore some of the information, basing our conclusions only on what remains. In other words, we must be <em>non-ideological</em>.</li>
<li>Equivalent states of knowledge must be represented by equivalent plausibility assignments. This is another form of internal consistency.</li>
</ol>
<p>Jaynes demonstrates that the only way to satisfy these conditions is to follow the structure of probability theory, and that any process that does not follow this structure violates one of the conditions above.</p>
<section id="the-basic-rules-of-probability" class="level3">
<h3 class="anchored" data-anchor-id="the-basic-rules-of-probability">The basic rules of probability</h3>
<p>For a complete description of the rules of probability, and their application in general statistical inference there are several books available, one of which from the present author <span class="citation" data-cites="Blais:2014aa">[@Blais:2014aa]</span>. We will need to establish a basic set of notation and mathematics in order to address the concepts. This notation will in some cases make clear and condensed much longer expositions of the same concepts in English (due to the terseness of mathematics). In other cases, it will provide a systematic framework for exploring disparate problems, in order to see the connection to all rational thought. We begin by describing the rules of probability, and some of their consequences.</p>
<p>When we write <span class="math inline">\(P(A)\)</span> the “<span class="math inline">\(P\)</span>” stands for “probability” and “<span class="math inline">\(A\)</span>” is some proposition or claim. We will be in the habit of naming sentences or statements with a short-hand of a single letter, like <span class="math inline">\(A \equiv\)</span> “<em>I draw an Ace from a well-shuffled, typical 52-card deck of cards</em>”<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>.</p>
<p>We then can talk about the probability of this statement being true with <span class="math inline">\(P(A)\)</span>, which is a summary of “<em>the probability that if I draw a card from a well-shuffled, typical 52-card deck of cards that I will draw an Ace.</em>” The shorthand allows us to write some general statements in a small amount of space.</p>
<p>Instead of using real-life examples to start, I prefer to use examples from simple card games. Using playing cards has several distinct advantages:</p>
<ol type="1">
<li>most people are comfortable with the concept of uncertainty in card games</li>
<li>a deck of cards is a <em>small</em> system</li>
<li>the <em>probabilities</em> are a direct parallel with <em>fractions</em> of card counts, making the subject more intuitive</li>
<li>a deck of cards is amenable to pictures</li>
</ol>
<section id="rule-1-definition-rule" class="level4">
<h4 class="anchored" data-anchor-id="rule-1-definition-rule">Rule 1 (Definition rule):</h4>
<p>The probability of a proposition or statement, e.g.&nbsp;<span class="math inline">\(P(A)\)</span>, is a number between 0 and 1, representing the strength of belief in a statement, <span class="math inline">\(A\)</span>.<br>
<span class="math display">\[
\begin{aligned}
P(A)=&amp;0 \,\text{certainly false}\\
P(A)=&amp;1 \,\text{certainly true}\\
0 &lt;  P(A) &lt; &amp; 1  \,\text{degrees of belief}
\end{aligned}
\]</span></p>
<p>The following picture shows a way to visualize this, with a “Universe” of all possibilities and the subset, which is our particular statement as a fraction of the total.</p>
<p><img src="../images/image-20190402142143483.png" class="img-fluid" width="200"></p>
<p>Although this probability is <em>estimated</em> by the fraction of Aces in a deck of cards, whenever we write probabilities we are referring to a measure of the strength of one’s belief in the statement. Thus, when we write that <span class="math inline">\(P(A)= 4/52 = 0.077\)</span> this probability means that you believe it to be unlikely – but not extremely unlikely – that you draw an Ace from a well-shuffled deck (see the Rough guide for the conversion of qualitative labels to probability values in Table 1 <a href="#table-1"></a> at the end of the chapter). This belief, as we will see, is not just a <em>guess</em> but is something arrived at through proper rational processes, or in other words, by adhering strictly to the rules of probability.</p>
</section>
</section>
<section id="a-bit-more-about-the-deck-of-cards-analogy" class="level3">
<h3 class="anchored" data-anchor-id="a-bit-more-about-the-deck-of-cards-analogy">A bit more about the deck-of-cards analogy</h3>
<p>We are using the deck of cards to be analogous to the real world. While there are things we know about the real world there is a lot of uncertainty as well, just like the uncertainty of the deck of cards. We can gather evidence in the real world, to better know what the truth is, and analogously we can draw cards from the deck to better know what the properties of the deck is, i.e.&nbsp;if it is well-shuffled, is a standard 52-card deck or a deck of Tarot cards, etc… As in the real world, we can propose <em>models</em> or simplified descriptions of what we think the deck is, and we can perform tests of these models by drawing from the deck and comparing to what we expect from the models. The methods of science do this with nature itself, by arranging situations where the observations will possibly rule out some models in favor of others, so that we get closer to the truth. The same rules of probability apply in all of these cases, but given the intuitive nature of a deck of cards, it is easier to see them applied in this simple system.</p>
<section id="rule-2-negation-rule" class="level4">
<h4 class="anchored" data-anchor-id="rule-2-negation-rule">Rule 2 (Negation rule):</h4>
<p>The negation rule states that a proposition is either true or its negation (i.e.&nbsp;direct opposite) is true. <span class="math display">\[
P(A) + P({\rm\bf not}\, A) = 1
\]</span></p>
<p>The following picture shows a universe of all possibilities and the subset (<span class="math inline">\(A\)</span>) which is our particular statement as a fraction of the total, along with the <em>opposite</em> of this subset (<strong>not</strong> <span class="math inline">\(A\)</span>) which adds up to the total.</p>
<p><img src="../images/image-20190402142940710.png" class="img-fluid" width="200"></p>
<p>In other words, either a statement is true or its negation is true. <span class="math display">\[
\begin{aligned}
A&amp;\equiv\left[\,\text{"you will draw an Ace from a deck of cards"}\right. \\
P(A)+P(\mathbf{not}\, A)&amp;=1 \\
\frac{1}{13} + \frac{12}{13} &amp;=1
\end{aligned}
\]</span> means that you can be <em>certain</em> (i.e.&nbsp;probability equal to 1) that when you draw a card from a deck, it will either be an Ace or it won’t be an Ace. This all seems rather obvious, and you may be wondering why we even bring it up. Surprisingly, this “<em>obvious</em>” property becomes a source of one of the most common logical fallacies - the either-or fallacy.</p>
<p>Notice how this occurs. The following is correct logical inference: <span class="math display">\[
\begin{aligned}
B&amp;\equiv\left[\text{"a playing card drawn from a deck is black"}\right. \\
P(B)+P(\mathbf{not}\, B)&amp;=1
\end{aligned}
\]</span> means that, if you draw a playing card from a deck, you can be <em>certain</em> that it is either black or it is not-black. This is true no matter what kind of deck of cards you are dealing with, even if it contains no black cards! The following, however, is <em>not</em> a correct logical inference: <span class="math display">\[
\begin{aligned}
B\equiv&amp;\left[\text{"a playing card drawn from a deck is black"}\right. \\
R\equiv&amp;\left[\text{"a playing card drawn from a deck is red"}\right. \\
P(B)+P(R)=&amp;1 \leftarrow \text{this is incorrect}
\end{aligned}
\]</span> The key point here is that “not-black” is not the same as “red” except in those cases where you can be <em>certain</em> that there are only those two possibilities. One has to be on the lookout for hidden possibilities - perhaps one has a <em>Five Crowns</em> deck<span class="citation" data-cites="fivecrowns2023">[@fivecrowns2023]</span> which has green and yellow cards as well? Failure of imagination can easily lead to accidental either-or logical failures. Statements like “You’re either with us or against us!” (no third option?) and “You could either pursue your dream job or stay where you are and be miserable for the rest of your life.” (again, no other options?) serve as a reminder to recognize this lack of imagination on our part.</p>
</section>
<section id="rule-3-conjunction-rule" class="level4">
<h4 class="anchored" data-anchor-id="rule-3-conjunction-rule">Rule 3 (Conjunction rule):</h4>
<p>The conjunction rule defines how we handle two propositions being true at the same time, relating them to the probabilities of the individual propositions <em>alone</em> and the probabilities of each one assuming the other is true, also called the <em>conditional</em> probability. The latter probability captures how the two propositions are related. <span class="math display">\[
\begin{aligned}
P(A \,\mathbf{and}\, B) = P(B|A)P(A)
\end{aligned}
\]</span></p>
<p>which is the probability of two statements both being true, A <strong>and</strong> B. We define a new symbol, <span class="math inline">\(|\)</span>, which should be read as “given.” When there is information given, we call this probability <em>conditional</em> on that information. We can represent the conjunction as the <em>overlap</em> in the following picture:</p>
<p><img src="../images/image-20190402145057643.png" class="img-fluid" width="200"></p>
<p>The numbers in the picture are coming from the propositions <span class="math inline">\(A\equiv\)</span> “you will draw an Ace from a deck of cards” and <span class="math inline">\(B\equiv\)</span> “a playing card drawn from a deck is black”</p>
<p>The conditional statements are like restricting the universe to the small part of what you’re “given” (i.e.&nbsp;what’s on the right-hand side of the bar symbol, <span class="math inline">\(|\)</span>). For example, <span class="math inline">\(P(A|B)\)</span>, is the probability of <span class="math inline">\(A\)</span> if you restrict your cases to those satisfying <span class="math inline">\(B\)</span> (see the right-hand rectangle in the following picture) and <span class="math inline">\(P(B|A)\)</span>, is the probability of <span class="math inline">\(B\)</span> if you restrict your cases to those satisfying <span class="math inline">\(A\)</span> (see the middle rectangle in the picture):</p>
<p><img src="../images/image-20190402150724049.png" class="img-fluid" width="300"></p>
<p>The conjunction rule in this case means that the probability of you drawing a black Ace is related to the probability of you drawing an Ace from a collection of black cards (i.e.&nbsp;“given that the card is black”, <span class="math inline">\(P(A|B)\)</span>) and the probability that you will draw a black card at all (<span class="math inline">\(P(B)\)</span>). It is also equal to the probability of you drawing a black card from a collection of Aces (i.e.&nbsp;“given that the card is an Ace”, <span class="math inline">\(P(B|A)\)</span>) and the probability that you will draw an Ace at all (<span class="math inline">\(P(A)\)</span>).</p>
<p>Numerically we have <span class="math display">\[
\begin{aligned}
P(A) &amp;= \frac{4}{52}&amp; \text{ (probability of Ace out of all cards)}\\
P(B) &amp;= \frac{1}{2}&amp; \text{ (probability of black out of all cards)}\\
P(A|B) &amp;= \frac{2}{26}&amp; \text{ (probability of Ace out of black cards)}\\
P(B|A) &amp;= \frac{2}{4}&amp; \text{ (probability of black out of Ace cards)}
\end{aligned}
\]</span> From which follows the probability of having a black Ace in two mathematically equivalent ways, <span class="math display">\[
\begin{aligned}
P(A\,\mathbf{and}\, B) &amp;=P(A|B)P(B) = \frac{2}{26}\times \frac{1}{2} = \frac{1}{26}
\end{aligned}
\]</span> and <span class="math display">\[
\begin{aligned}
P(A\,\mathbf{and}\, B) &amp;=P(B|A)P(A) = \frac{2}{4}\times \frac{4}{52} = \frac{1}{26}
\end{aligned}
\]</span> Mathematically, it can be seen that <span class="math inline">\(P(A \,\mathbf{and}\, B)\)</span> is always lower than <span class="math inline">\(P(A)\)</span> unless we are <em>certain</em> that the other statement, <span class="math inline">\(B\)</span>, is true – the conjunction of two things is inherently (and mathematically) less probable than the individual components. Failure to recognize this leads to the <em>conjunction fallacy</em>. The most common example of this fallacy presented is as follows<span class="citation" data-cites="wiki_conjunction_fallacy:2023aa">[@wiki_conjunction_fallacy:2023aa]</span>,</p>
<blockquote class="blockquote">
<p><em>Linda is 31 years old, single, outspoken, and very bright. She majored in philosophy. As a student, she was deeply concerned with issues of discrimination and social justice, and also participated in anti-nuclear demonstrations.</em></p>
<p>Which is more probable?</p>
<ol type="1">
<li>Linda is a bank teller.</li>
<li>Linda is a bank teller and is active in the feminist movement.</li>
</ol>
</blockquote>
<p>Most people lead towards (2), but the actual answer is (1) because the combination of two things (a bank teller <em>and</em> is a feminist) is a smaller subset and is thus less likely<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>.</p>
<p>There are a few points to be made about the approach we’ve been using so far, which become important in later examples.</p>
<ul>
<li><p>Notice how concise the description is – the math can summarize the relationship between several concepts with few words or symbols.</p></li>
<li><p>As we’ve seen, the conjunction of two things is inherently (and mathematically) less probable than the individual components, sometimes with unintuitive consequences.</p></li>
<li><p>If there is more than one way to reason properly to an answer, those different ways must come to the same answer. This is a good check to see that you are thinking properly when you see the same answers, but it is also a way to distinguish two methods that are in fact not equivalent even if they seem to be – they come to different answers.</p></li>
<li><p>Two statements are considered <em>independent</em> if knowledge of one gives you no more information about the other. In probabilistic terms, this means that <span class="math inline">\(P(B|A)=P(B)\)</span> – knowing <span class="math inline">\(A\)</span> is true doesn’t make the probability of <span class="math inline">\(B\)</span> any more or less. Flipping a coin a second time is still going to be 50-50 heads-tails whether you flipped heads the first time or not. Drawing a second card from the top of a deck is a little less likely to be a black card if you drew a black card on the first time – knowledge of previous cards drawn tells you information about the probabilities for the second<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>. Independence becomes important in the evaluation of evidence because it changes how evidence can be accumulated.</p></li>
</ul>
<ul>
<li>In the case of <em>independent</em> statements, the conjunction rule simplifies to</li>
</ul>
<p><span class="math display">\[
P(A\,\mathbf{and}\,B) = P(A)\cdot P(B) \,\,\,\text{  (independent)}
\]</span></p>
<ul>
<li>The <em>general case</em> of the conjunction rule looks like</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
P(A\,\mathbf{and}\,B\,\mathbf{and}\,C\,\mathbf{and}\,D)=&amp;P(A)\times P(B|A)\times P(C|A\,\mathbf{and}\,B)\times \\
&amp;P(D|A\,\mathbf{and}\,B\,\mathbf{and}\,C)
\end{aligned}
\]</span></p>
</section>
<section id="rule-4-bayes-rule" class="level4">
<h4 class="anchored" data-anchor-id="rule-4-bayes-rule">Rule 4 (Bayes’ rule)</h4>
<p>This rule is perhaps the most obtuse to see for the first time, but is by far the most important rule of them all, so it is worth the effort.<br>
<span class="math display">\[
\begin{aligned}
P(A|B) =&amp; \frac{P(B|A)P(A)}{P(B)}
\end{aligned}
\]</span> Mathematically, it is just a rewriting of the conjunction rule above. Its deeper meaning can be seen when rewritten in a somewhat more elaborated form describing our belief in an explanation given some data,</p>
<p><span class="math display">\[\begin{aligned}
\underbrace{P({\rm explanation}|{\rm data})}_{\rm posterior}&amp;=&amp; \frac{\underbrace{P({\rm data}|{\rm explanation})}_{\rm likelihood}\underbrace{P({\rm explanation})}_{\rm prior}}{\underbrace{P({\rm data})}_{\rm total\,proability}}
\end{aligned}\]</span></p>
<p>where each term is described more fully as</p>
<ul>
<li><span class="math inline">\(P({\rm explanation})\)</span> – the probability the explanation is correct <em>prior</em> to seeing the data. The term itself is often called the <em>prior</em>, and represents your beliefs before you see the data. Typically, more complex explanations are less likely a-<em>prior</em>i than simpler ones. I will use the term <em>model</em> in place of explanation in most of this book, but it means the same thing.</li>
<li><span class="math inline">\(P({\rm explanation}|{\rm data})\)</span> – the probability the explanation is correct <em>after</em> seeing the data (<em>a-posteriori</em>). The term itself is often called the <em>posterior</em> for this reason, and represents your updated beliefs once you have data. Thus, Bayes’ rule is a mathematical expression of <em>learning</em> from evidence.<br>
</li>
<li><span class="math inline">\(P({\rm data}|{\rm explanation})\)</span> – the probability that the data can be explained with <em>this particular explanation</em>. The term itself is often called the <em>likelihood</em>, and can be thought of as a measure of how well the explanation fits the data. If the explanation fits the data well, this number will be high, for example. If it fails to explain the data, this number will be low. Although related to our final (<em>posterior</em>) belief, it is not equivalent. An explanation that fits the data well may be very unlikely as our best explanation just because that explanation was extremely unlikely in the first place (i.e.&nbsp;before we saw the data, aka the <em>prior</em> was low). Saying that gremlins cause our car to run may explain the observation of our running but is unlikely becaue the existence of gremlins is unlikely before we make any observations on our car.</li>
<li><span class="math inline">\(P({\rm data})\)</span> – the total probability of the data, regardless of the explanation. It is easiest to understand this term with an examples below. This term doesn’t play major role for us, and is simply there to make sure that the probabilities across all explanations add up to one, mathematically.</li>
</ul>
<p>Imagine we are playing a game with several small decks of cards, defined here:</p>
<ul>
<li><span class="math inline">\(E_1: A\spadesuit, 2\heartsuit, 3\spadesuit,4\spadesuit\)</span></li>
<li><span class="math inline">\(E_2: A\heartsuit, 2\heartsuit, 3\spadesuit, 4\spadesuit\)</span></li>
<li><span class="math inline">\(E_3: A\heartsuit,2\heartsuit, 2\heartsuit,4\spadesuit\)</span></li>
<li><span class="math inline">\(E_4: A\spadesuit,3\spadesuit, 3\spadesuit, 4\spadesuit\)</span></li>
</ul>
<p>Where <span class="math inline">\(E\)</span> is denoting a deck or, more generally, an <em>explanation</em> for the data we will collect by drawing cards. In the game, someone has handed us one of the decks (i.e.&nbsp;<span class="math inline">\(E_1\)</span>, <span class="math inline">\(E_2\)</span>, <span class="math inline">\(E_3\)</span> or <span class="math inline">\(E_4\)</span>) but <em>we don’t know at all which one it is</em>. The analogy here is that the universe is set up with a set of rules that we are trying to determine. Thus, deciding on which deck we are holding is analogous to deciding which universe we are actually in, given our observations of the universe. In other words, providing an <em>explanation</em> of the data is really about determining which of the many possible universes we are in.</p>
<p><img src="../images/image-20190402152206104.png" class="img-fluid" width="400"></p>
<p>We then draw the top card, observe that it is a <span class="math inline">\(3\spadesuit\)</span>, and see if we can reason about which deck is likely to be the one we are holding. I invited the reader to weight the different explanations, approximately, yourself before we do the math. We choose such a small, simple system because it is easy to intuit the answers without the math. This intuition can provide a scaffold for understanding the mathematics, which can be used in more complex examples where one <em>doesn’t</em> have a strong intuition. It is therefore worth going through at least one example in detail.</p>
<p>To begin, we need to assign the probabilities of the four cases <em>prior</em> to the data. Given total ignorance of which deck was chosen– we know that there are 4 possibilities but have no idea about anything more about the selection process – we assign equal probabilities to the four cases<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></p>
<p><span class="math display">\[\begin{aligned}
P(E_1)&amp;=&amp;1/4 \\
P(E_2)&amp;=&amp;1/4 \\
P(E_3)&amp;=&amp;1/4 \\
P(E_4)&amp;=&amp;1/4
\end{aligned}\]</span></p>
<p>Note that in this example we know what cards are in each deck – we know, for example, that there are no spades in <span class="math inline">\(E_3\)</span> – we just don’t know which deck we were given. Here we describe our intuitions, with the mathematics in parallel below. Since we drew a <span class="math inline">\(3\spadesuit\)</span>, our intuition says that this should rule out <span class="math inline">\(E_3\)</span> altogether. Further, it says <span class="math inline">\(E_4\)</span> should be more likely than the other remaining two because it contains the observed card, <span class="math inline">\(3\spadesuit\)</span>, more than one time – it is easier to get that particular card from the fourth deck than the others.</p>
<p>The mathematics would look like this</p>
<p><span class="math display">\[\begin{aligned}
P(E_1|3\spadesuit)=&amp;\frac{P(3\spadesuit|E_1)P(E_1)}{P(3\spadesuit)}\begin{array}{c}\ \\\leftarrow\text{this term the same in all}\end{array}\\
P(E_2|3\spadesuit)=&amp;\frac{P(3\spadesuit|E_2)P(E_2)}{P(3\spadesuit)}\\
P(E_3|3\spadesuit)=&amp;\frac{P(3\spadesuit|E_3)P(E_3)}{P(3\spadesuit)}\\
P(E_3|3\spadesuit)=&amp;\frac{P(3\spadesuit|E_4)P(E_4)}{P(3\spadesuit)}
\end{aligned}\]</span></p>
<p>where we already have the priors, one for each model,</p>
<p><span class="math display">\[\begin{aligned}
P(E_1)=P(E_2)=P(E_3)=P(E_4)=1/4
\end{aligned}\]</span></p>
<p>Further, we have the likelihood term,</p>
<p><span class="math display">\[\begin{aligned}
P(3\spadesuit|E_1) = 1/4
\end{aligned}\]</span></p>
<p>because one card out of 4 in the first deck is the <span class="math inline">\(3\spadesuit\)</span>. Likewise, we have the other likelikhood terms for the other models,</p>
<p><span class="math display">\[\begin{aligned}
P(3\spadesuit|E_2) &amp;= 1/4\\
P(3\spadesuit|E_3) &amp;= 0 \\
P(3\spadesuit|E_4) &amp;= 2/4
\end{aligned}\]</span></p>
<p>Finally we have the total probability term,<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a></p>
<p><span class="math display">\[\begin{aligned}
P(3\spadesuit) = 4/16
\end{aligned}\]</span></p>
<p>because there are four “<span class="math inline">\(3\spadesuit\)</span>” cards out of all the 16 in the game. Plugging these numbers into the above equations, and performing the arithmetic, we have <span class="math display">\[\begin{aligned}
P(E_1|3\spadesuit)&amp;=\frac{(1/4)\times (1/4)}{(4/16)} = 1/4 \\
P(E_2|3\spadesuit)&amp;=\frac{(1/4)\times (1/4)}{(4/16)} = 1/4 \\
P(E_3|3\spadesuit)&amp;=\frac{(0)\times (1/4)}{(2/12)} = 0 \\
P(E_4|3\spadesuit)&amp;=\frac{(2/4)\times (1/4)}{(4/16)} = 1/2 \\
\end{aligned}\]</span></p>
<p>which perfectly matches our intuition – <span class="math inline">\(E3\)</span> is certainly false, and <span class="math inline">\(E_4\)</span> is more likely than the other two. Notice further that <span class="math inline">\(P(3\spadesuit|E_1)\)</span> is another way of saying “how well is the observation of a <span class="math inline">\(3\spadesuit\)</span> explained by the idea that we’re holding the first deck?” The entire process of starting with prior beliefs (e.g.&nbsp;<span class="math inline">\(P(E_1)\)</span>) and updating them with an observation (e.g.&nbsp;<span class="math inline">\(3\spadesuit\)</span>) yielding a posterior belief (e.g.&nbsp;<span class="math inline">\(P(E_1|3\spadesuit)\)</span>) can then be thought of as updating our initial beliefs with the new evidence.</p>
<blockquote class="blockquote">
<p><em>Any process of reasoning, in any field whatsoever, is either consistent with this process of calculation or it is not rational.</em></p>
</blockquote>
<p>It is for this reason that we explore this process in such detail.</p>
<p>On another front, an alternate way to have calculated the shared bottom term, <span class="math inline">\(P(3\spadesuit)\)</span>, is the following totally long-winded and complicated way</p>
<p><span class="math display">\[\begin{aligned}
P(3\spadesuit) =&amp; P(3\spadesuit|E_1)P(E_1) + P(3\spadesuit|E_2)P(E_2)+ \\
&amp;P(3\spadesuit|E_3)P(E_3)+ P(3\spadesuit|E_4)P(E_4)\\
=&amp;(1/4)\times (1/4) + (1/4)\times (1/4) + (0)\times (1/3)+ (2/4)\times (1/4) \\
=&amp; 4/16
\end{aligned}\]</span></p>
<p>Why would one write it in this seemingly over-complex fashion? Because it makes it easier to say, in words, what this term is doing. It is the sum of all of the probabilities for how well each explanation accounts for the data scaled by how likely that explanation was before seeing the data. In other words, proper rational inference requires that you re-weight the strength of your beliefs in an explanation not just by how well that explanation describes your observations, but also by how intrinsically likely that explanation is before your observations and <em>how well all of the alternatives perform on those same observations</em>.</p>
<p><img src="../images/bayes1.png" class="img-fluid" width="400"></p>
<p>An observation can be very well described by a particular explanation, but if it can be equivalently explained by other, simpler, explanations, then your belief in that more-complex explanation may in fact become <em>weaker</em> with the new observation (i.e.&nbsp;its probability could go down).</p>
</section>
</section>
<section id="on-simplicity" class="level2">
<h2 class="anchored" data-anchor-id="on-simplicity">On simplicity</h2>
<p>Ockham’s razor, which is the philosophical idea that simpler theories are preferred, is a consequence of Bayes’ rule when comparing models of differing complexity <span class="citation" data-cites="Jeffreys1991sharpening">[@Jeffreys1991sharpening]</span>. We can see this by extending the card game example. We extend it two ways – we draw another card, and we add a fifth model. The data now include a draw of a <span class="math inline">\(3\spadesuit\)</span> followed by a <span class="math inline">\(4\spadesuit\)</span>.</p>
<p><img src="../images/Pasted_image_20220114105745.png" class="img-fluid" width="400"></p>
<p>Instead of giving the specific cards in the <span class="math inline">\(E_5\)</span> deck, we are simply told</p>
<ul>
<li><p><span class="math inline">\(E_5:\)</span> the deck can be any one of the decks shown:</p>
<blockquote class="blockquote">
<p>(<span class="math inline">\(A\spadesuit, 2\spadesuit, 3\spadesuit, 3\spadesuit\)</span>), (<span class="math inline">\(A\spadesuit, 3\spadesuit, 3\spadesuit, 4\spadesuit\)</span>),(<span class="math inline">\(A\spadesuit, 3\spadesuit, 3\spadesuit, 3\spadesuit\)</span>),(<span class="math inline">\(4\spadesuit, 4\spadesuit, 3\spadesuit, 4\spadesuit\)</span>)</p>
</blockquote></li>
</ul>
<p>This explanation of the game is what is called <em>plastic</em><a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a> - a value in the model that is not specified ahead of time, but can be <em>fit</em> to the data, and an optimum value found. We could potentially think like the following. Depending on the data, we may infer a different value for the number of <span class="math inline">\(3\spadesuit\)</span> in this deck. It may be heavily loaded toward <span class="math inline">\(3\spadesuit\)</span> and <span class="math inline">\(4\spadesuit\)</span>, which would make <span class="math inline">\(E_{5}\)</span> explain the data very well; however it may have few or none, and not explain the data well or at all. Clearly, once you observe a <span class="math inline">\(3\spadesuit\)</span>, the “best” value for this deck is to have three of them out of the four cards - making it more likely than the previously best explanation, <span class="math inline">\(E_4\)</span>, which only had two out of four. Once we see the second card, the <span class="math inline">\(4\spadesuit\)</span>, the new deck <span class="math inline">\(E_5\)</span> can explain that as well! In fact, <span class="math inline">\(E_5\)</span> contains <span class="math inline">\(E_4\)</span> as a subset, so in some way we might think that <span class="math inline">\(E_5\)</span> explains the data at least as well – if not better – than <span class="math inline">\(E_4\)</span>, no matter what the data..</p>
<p>However, this process of reasoning violates the laws of probability by not taking our uncertainty into account due to the multiple choices of decks in <span class="math inline">\(E_5\)</span>. For simplicity, let’s just consider the two decks in question, <span class="math inline">\(E_4\)</span> and <span class="math inline">\(E_5\)</span>, and play the game with them (again, as before, drawing a <span class="math inline">\(3\spadesuit\)</span> from the top and then drawing a second card, the <span class="math inline">\(4\spadesuit\)</span>).</p>
<ul>
<li><span class="math inline">\(E_4\)</span>: <span class="math inline">\(A\heartsuit\)</span>,<span class="math inline">\(3\spadesuit\)</span>, <span class="math inline">\(3\spadesuit\)</span>, <span class="math inline">\(4\spadesuit\)</span></li>
<li><span class="math inline">\(E_5:\)</span> the deck can be any one of the decks shown:</li>
</ul>
<blockquote class="blockquote">
<p><span class="math inline">\([A\spadesuit, 2\spadesuit, 3\spadesuit, 3\spadesuit]\)</span>, <span class="math inline">\([A\spadesuit, 3\spadesuit, 3\spadesuit, 4\spadesuit]\)</span>,<span class="math inline">\([A\spadesuit, 3\spadesuit, 3\spadesuit, 3\spadesuit]\)</span>,<span class="math inline">\([4\spadesuit, 4\spadesuit, 3\spadesuit, 4\spadesuit]\)</span></p>
</blockquote>
<p>We set up the calculation as before,</p>
<p><span class="math display">\[\begin{aligned}
P(E_4|3\spadesuit,4\spadesuit)&amp;=&amp;\frac{P(3\spadesuit,4\spadesuit|E_4)P(E_4)}{P(3\spadesuit,4\spadesuit)}\\
P(E_5|3\spadesuit,4\spadesuit)&amp;=&amp;\frac{P(3\spadesuit,4\spadesuit|E_5)P(E_5)}{P(3\spadesuit,4\spadesuit)}
\end{aligned}\]</span></p>
<p>We defer the calculation of the shared term, <span class="math inline">\(P(3\spadesuit,4\spadesuit)\)</span>, and focus on the numerators of both calculations.<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a> First the one for <span class="math inline">\(E_4\)</span> (and remember, we have only two decks here, so we’ll have a prior of <span class="math inline">\(P(E_4)=P(E_5)=1/2\)</span>),</p>
<p><span class="math display">\[\begin{aligned}
P(E_4|3\spadesuit,4\spadesuit)&amp;\sim P(3\spadesuit,4\spadesuit|E_4)P(E_4)\\
&amp;=(2/4)\times (1/3) \times (1/2) = 1/12
\end{aligned}\]</span> Where the second draw (the <span class="math inline">\(4\spadesuit\)</span>) is out of <em>3 cards</em>, so we have <span class="math inline">\(1/3\)</span> in the multiply.</p>
<p>Next with the <span class="math inline">\(E_5\)</span> deck,</p>
<p><span class="math display">\[
\begin{aligned}
P(E_5|3\spadesuit,4\spadesuit)&amp;\sim P(3\spadesuit, 4\spadesuit|E_5)P(E_5)\\
&amp;=P(3\spadesuit, 4\spadesuit|E_5)\times (1/2) \\
\end{aligned}
\]</span> where the term <span class="math inline">\(P(3\spadesuit, 4\spadesuit|E_5)\)</span> is arrived at by breaking it into the four possibilities – one for each of the decks. Each of the possibilities (all equally likely, because we are given no other information) has the form of the number of <span class="math inline">\(3\spadesuit\)</span> divided by 4 times the number of <span class="math inline">\(4\spadesuit\)</span> divided by 3 (remember – it’s the second card drawn, out of 3 remaining cards) for each deck, times 1/4 because there are 4 total possible decks to consider, for example <span class="math display">\[
\begin{aligned}
P(3\spadesuit,4\spadesuit|E_5\text{ with } [A\spadesuit, 2\spadesuit, 3\spadesuit, 3\spadesuit])P(E_5\text{ with } [A\spadesuit, 2\spadesuit, 3\spadesuit, 3\spadesuit]|E_5) =&amp; \underbrace{(2/4)}_{\text{two } 3\spadesuit s} \times \underbrace{(0/3)}_{\text{zero } 4\spadesuit s} \times(1/4) \\
P(3\spadesuit,4\spadesuit|E_5\text{ with } [A\spadesuit, 3\spadesuit, 3\spadesuit, 4\spadesuit])P(E_5\text{ with } [A\spadesuit, 3\spadesuit, 3\spadesuit, 4\spadesuit]|E_5) =&amp; \underbrace{(2/4)}_{\text{two } 3\spadesuit s} \times \underbrace{(1/3)}_{\text{one } 4\spadesuit s} \times(1/4) \\
\vdots &amp;
\end{aligned}
\]</span></p>
<p>Doing the same for all the possibilities, we get for the <span class="math inline">\(E_5\)</span> numerator,</p>
<p><span class="math display">\[
\begin{aligned}
P(3\spadesuit, 4\spadesuit|E_5)P(E_5)&amp;=
\left[(2/4)\times (0/3)\times (1/4) + (2/4)\times (1/3)\times (1/4) +  \right. \\
&amp;\left. (3/4)\times (0/3)\times (1/4) +  (1/4)\times (3/3)\times (1/4)\right]\times (1/2) \\
&amp;=5/96
\end{aligned}
\]</span></p>
<p>Finally, we can get the shared term,</p>
<p><span class="math display">\[\begin{aligned}
P(3\spadesuit, 4\spadesuit)= 1/12 + 5/96 = 13/96
\end{aligned}\]</span></p>
<p>and the probabilities of each of the decks, given the observation of a <span class="math inline">\(P(3\spadesuit, 4\spadesuit)\)</span>,</p>
<p><span class="math display">\[\begin{aligned}
P(E_4|3\spadesuit, 4\spadesuit)&amp;=&amp;\frac{1/12}{13/96} = 8/13\\
P(E_5|3\spadesuit, 4\spadesuit)&amp;=&amp;\frac{5/96}{13/96} = 5/13
\end{aligned}\]</span></p>
<p>This means that, although <span class="math inline">\(E_5\)</span> contains the <em>possibility</em> of a better fit to the data, it is less <em>probable</em> because it has a flexible parameter that is unspecified <em>before</em> the data. Even more interesting, is that <span class="math inline">\(E_5\)</span> actually <em>contains</em> <span class="math inline">\(E_4\)</span> as a possibility! In other words, if you have an explanation which is not specific but can adjust to the data only after seeing it, there is a danger in accepting that explanation over one that is specific and doesn’t change its prediction after the data. The proper use of the rules of probability help guard against this danger. In religious contexts, an example of this happens when addressing the efficacy of prayer. Someone might reason as follows, “if the prayer works then God chose to act, otherwise God had a reason to withhold action”. This is a poor explanation, because it is not specific and adjusts to the data only after the fact – one couldn’t make a prediction with this model of the world.</p>
<p>We can scale this problem up, to include the following explanation,</p>
<ul>
<li><span class="math inline">\(E_6\)</span>: A collection of every possible 4-card deck drawn from a regular deck of 52 cards, all turned into spades (so there are 4 of every rank).</li>
</ul>
<p>This new deck is <em>extremely</em> flexible, including a deck <span class="math inline">\([4\spadesuit, 4\spadesuit, 3\spadesuit, 3\spadesuit]\)</span> which fits the data as precisely as if it could be designed, and any other spades draw we could think of. There are 270725 such decks, and doing the same calculation as above we get that <span class="math inline">\(E_6\)</span> is less likely than either of the other decks we considered by more than a factor of 100. <span class="math inline">\(E_6\)</span> is consistent with nearly <em>any</em> data we observe, and in so being, it pays a penalty in our confidence that it is true.</p>
<p>When we prefer a “simpler” model with Ockham’s razor, simpler means <em>fewer adjustable parameters</em>. It also means that the predictions are both <em>specific</em> and not <em>overly plastic</em>. For example, a hypothesis which is consistent with the observed data, but also would be consistent if the data were the opposite would be overly plastic. An example of an infinitely plastic “explanation” is “<em>magic did it</em>.” Because it can “explain” anything (given that it is consistent with any possible observation), it thus explains nothing. Conspiracy theorists suffer from this problem, because any counter-evidence provided get lumped into the conspiracy. If you claim that we staged the moon landing, and someone provides photographs of the astronauts on the moon, then you can just say that the astronaut and the photographer are “in on the conspiracy” – the model gets adjusted after the fact and is <em>overly plastic</em>.</p>
<p>Notice also that <em>simpler</em> does not necessarily mean having fewer parts or having an easier description. For <span class="math inline">\(E_4\)</span>, I had to specify each card, whereas for <span class="math inline">\(E_6\)</span>, I merely said “every possible 4-card deck”. The complexity of the explanation comes from its <em>flexibility</em>. In another context, fitting a line to data you need to specify the <em>slope</em> and the <em>intercept</em>. A model where the slope and intercept are determined from other considerations than the data (and are thus not <em>fit</em> to the data) is more simple than one where we only fit the intercept and have zero slope. The complexity comes from the flexibility a model has once we are presented with data.</p>
</section>
<section id="on-belief-knowledge-and-proof" class="level2">
<h2 class="anchored" data-anchor-id="on-belief-knowledge-and-proof">On belief, knowledge, and proof</h2>
<p>Clearly the terms belief, knowledge, and proof are related but it is the framework of probability that helps us be specific about their differences. We can summarize the situation with the following,</p>
<ul>
<li><em>Belief</em> is measured by probability. Higher probability is equivalent to stronger belief, and likewise, lower probability is equivalent to weaker belief.</li>
<li><em>Knowledge</em> is a subset of belief, described more specifically below.</li>
<li><em>Proof</em> refers specifically to the result of a <em>deductive</em> process. In this process, one starts with some (given) axioms, and can demonstrate <em>with certainty</em> (i.e.&nbsp;prove) a number of theorems (i.e direct consequences) from those axioms. Thus, the word proof should only be used in situations involving <em>certainty</em>, or in other words, probabilities of exactly 1 or exactly 0 only.</li>
</ul>
<section id="belief" class="level3">
<h3 class="anchored" data-anchor-id="belief">Belief</h3>
<blockquote class="blockquote">
<p>We say we believe a proposition <span class="math inline">\(A\)</span> when <span class="math inline">\(P(A)&gt;0.5\)</span>. We say we believe <em>strongly</em> in a proposition <span class="math inline">\(A\)</span> when <span class="math inline">\(P(A)&gt;0.95\)</span> or some other, somewhat arbitrary, high number. The strength of a belief is a <em>scale</em> measured by the probability assigned to that proposition.</p>
</blockquote>
<p>Everything we have covered so far in this book relates to belief. Notice that someone can have a <em>false</em> belief, if the information they are provided is incorrect. If we want to believe as many true things and as few false things as possible then we should look for ways to test our beliefs and challenge the information we are given. Belief, as used here, is different from <em>opinion</em>. When we use the word <em>opinion</em> we can simply mean <em>preference</em> (e.g.&nbsp;I like vanilla more than chocolate) which is not a belief. However I can also say I have an <em>opinion</em> about whether a political candidate is being honest, which is a usage equivalent to <em>belief</em> as long as the <em>opinion</em> is based on evidence and not just preference. This is yet another example of the vaguaries of the English language.</p>
</section>
<section id="knowledge" class="level3">
<h3 class="anchored" data-anchor-id="knowledge">Knowledge</h3>
<p>What is knowledge? Plato gave the following definition of knowledge:</p>
<blockquote class="blockquote">
<p>Knowledge is justified true belief. <span class="citation" data-cites="fine2003plato">[@fine2003plato]</span></p>
</blockquote>
<p>This is an unsatisfying definition because, it seems, in order to label anything as <em>knowledge</em> with this definition we’d need to be able to independently determine that the statement is true. This presupposes that there is some “outside” knowledge, but we have no access to that. I believe there is likely to be an absolute truth, but that we can never truly know what it is for certain . Howeverm I also believe that this is not such a big problem. It is a red herring to bring up 100% certainty for knowledge, because it is never achievable, and isn’t what we practically call knowledge. I prefer a definition inspired by Stephen J Gould:<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a></p>
<blockquote class="blockquote">
<p><em>In science, ‘fact’ can only mean confirmed to such a degree that it would be perverse to withhold provisional assent. `I suppose that apples might start to rise tomorrow, but the possibility does not merit equal time in physics classrooms.’</em> <span class="citation" data-cites="gould1981evolution">[@gould1981evolution]</span></p>
</blockquote>
<p>Where it says “fact,” read “knowledge.” Where it says “science” read “life.” The fact, or knowledge, that the Sun rises in the east and sets in the west is not due to a formal <em>proof</em> that this is always true, or will continue indefinitely into the future. It is an admission that the probability is so outrageously high, given the evidence of every other sun rise and sun set observed, and the further confirmation of models of the solar system, that it would be “perverse to withhold provisional assent.” We accept the claim as a practical matter, despite not being 100% certain, because of the overwhelming probabilities. This we call knowledge. It is thus never a problem to admit we lack certain knowledge, and it can be seen as an obvious diversion if anyone tries to argue in a manner that suggests it’s a problem.</p>
<p>Mathematically, we might write “knowledge of <span class="math inline">\(A\)</span>” as the “probability of proposition <span class="math inline">\(A\)</span> is very close to certain”, or equivalently, <span class="math inline">\(P(A)&gt;0.9999 \approx 1\)</span> where “<span class="math inline">\(\approx\)</span>” means <em>approximately</em>. Notice that we don’t need 100% certainty to claim knowledge, and that it is still possible for our “knowledge” to be wrong (although, by definition, it is highly unlikely for this to be the case).</p>
<p>We can ask the question, how did we come to this knowledge? The answer is simply, by applying the rules of probability! According to Bayes’ rule, we update our probabilities given the evidence. This can lead us to approach, but never equal, probability of 1. We can approach, but never achieve, complete certainty of any claim. Rationality only insists that we apply the rules of probability systematically.</p>
</section>
<section id="proof" class="level3">
<h3 class="anchored" data-anchor-id="proof">Proof</h3>
<p>Do <em>proof</em> and <em>evidence</em> mean the same thing? No, they don’t. There are two primary processes for rational inference – <em>deductive</em> and <em>inductive</em>. In <em>deductive</em> reasoning, one starts with some (given) axioms, and can demonstrate <em>with certainty</em> (i.e.&nbsp;prove) a number of theorems (i.e direct consequences) from those axioms. In <em>inductive</em> reasoning, one presents evidence or data which makes certain models either more or less likely – never to absolute certainty. Thus, the word “<em>proof</em>” should only be used in situations involving <em>certainty</em>, derived from axioms with logic. In this way, <em>deductive</em> reasoning is a subset of <em>inductive</em> for those cases where the probabilities are <em>exactly</em> 1 or <em>exactly</em> 0. <em>Induction</em> is just another name for the application of the rules of probability, so we have been doing that from the beginning of the book.</p>
<p>I realize that I’m being pedantic here because in common speech we use the word “proof” a little more loosely. We speak about “scientific proof” or “I won’t believe this without proof”. However, it is important to be specific about what one means here and I will insist through this book that the word “proof” be used only in the more restrictive sense. Everything else is just probabilities approaching proof. As a result, we have the following maxim,</p>
<blockquote class="blockquote">
<p><em>Proof</em> does not exist in science, only in math and philosophy.</p>
</blockquote>
<p>The only place you can have proof is where you have <em>axioms</em> (i.e.&nbsp;unprovable statements which are assumed to be true), and can then <em>prove</em> a number of consequences of those axioms. We can prove, for example, that the sum of the angles of a triangle is 180 degrees, if we start with the Euclidean axioms of geometry. Science doesn’t have axioms, and thus there are no proofs - there is only evidence. Unfortunately, we sometimes hear the term “proven scientifically,” even from people who should know better.<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a></p>
<p>As it applies to science, it has the following consequence</p>
<blockquote class="blockquote">
<p>All of the evidence in the universe cannot bring the probability of a scientific claim to certainty.</p>
</blockquote>
<p>To see this directly, imagine we have two (and only two) hypotheses for the earth - flat earth and round earth. We can write Bayes’ rule for the probability of each given the data. Note that these data includes things like the experience of airplane flight, Magellan’s trip, pictures from space - all of which could be faked! The flat earth hypothesis is not <em>logically</em> impossible, it’s just been overwhelmed by the evidence.</p>
<p><span class="math display">\[\begin{aligned}
P({\rm round}|{\rm data}) &amp;=&amp; \frac{P({\rm data}|{\rm round})P({\rm round})}{P({\rm data}|{\rm flat})P({\rm flat})+P({\rm data}|{\rm round})P({\rm round})}\\\\
P({\rm flat}|{\rm data}) &amp;=&amp; \frac{P({\rm data}|{\rm flat})P({\rm flat})}{P({\rm data}|{\rm flat})P({\rm flat})+P({\rm data}|{\rm round})P({\rm round})}
\end{aligned}\]</span></p>
<p>Notice that, no matter how well the round earth hypothesis explains the data (i.e.&nbsp;<span class="math inline">\(P({\rm data}|{\rm round})\approx 1\)</span>) and how unlikely you believe it is that the Earth is flat even <em>before</em> the data, (i.e.&nbsp;<span class="math inline">\(P({\rm flat})\ll 1\)</span>) as long as there is some <em>possible</em> (even if seriously contrived) way to explain the data with the flat earth hypothesis (i.e.&nbsp;<span class="math inline">\(P({\rm data}|{\rm flat}) \neq 0\)</span>) it is <em>mathematically impossible</em> to make the round earth hypothesis certain. All of the terms in both equations above are greater than 0 and less than 1 and thus the round-earth model isn’t 100% certain (i.e.<span class="math inline">\(P({\rm round}|{\rm data})&lt; 1\)</span>)</p>
<p>This does not mean that we can’t be <em>confident</em> of claims, only that we cannot have <em>absolute certainty of anything</em> in science (and therefore, in life in general). Anyone who doesn’t understand that does not understand science.</p>
<p>For it to be <em>reasonable to believe in something</em>, it must rise to a level of probability that you would label it as <em>belief</em>. Does this ever happen, or should this ever happen, with untrue things? Certainly. Here are a few that come to mind.</p>
<ul>
<li>the world is flat - as long as you are constrained to not live near the shore, or see a lunar eclipse</li>
<li>life is designed - before the advent of Darwin’s theory of natural selection</li>
<li>the Sun, and the stars, all go around the Earth - until the maturation of astronomy and physics</li>
</ul>
<p>In each of these cases, <em>at the time</em> there was in fact strong evidence for the (false) claims making it reasonable to believe them. It is no longer reasonable to believe these claims - the process of reason forces one to adjust the probabilities of the hypotheses given new evidence, and to discard those hypotheses that become too improbable.</p>
</section>
</section>
<section id="an-example-of-independence" class="level2">
<h2 class="anchored" data-anchor-id="an-example-of-independence">An example of independence</h2>
<p>The nature of independence comes up in many places so it is important to understand how it can affect inference. Recall that two statements are considered <em>independent</em> if knowledge of one gives you no more information about the other. In probabilistic terms, this means that <span class="math inline">\(P(B|A)=P(B)\)</span> – knowing <span class="math inline">\(A\)</span> is true doesn’t make the probability of <span class="math inline">\(B\)</span> any more or less. In the case of cards, if I constantly reshuffle the deck after each draw then knowing one card will not help you with the next.</p>
<p>I can easily make certain cards more or less likely by changing the process of drawing. If I always place cards the I draw from the top of the deck back at the bottom of the deck, then knowing I’ve drawn two Aces so far makes the drawing of Aces <em>less likely</em> in future draws. If however I place the cards back near the top of the deck (e.g.&nbsp;throwing them roughly into a pile that I draw from), then knowing I’ve drawn two Aces so far makes the drawing of Aces <em>more likely</em> in future draws.</p>
<p>If you are assuming (for simplicity) that information you’re getting from two different people is <em>independent</em> and it turns out that it isn’t, then you will not reach proper conclusions. It might be that the information is less reliable than you thought – that the second person only heard the information from the first, so you’re effectively getting it from one person. The equations would look like (focussing on the numerator of Bayes’ Rule) <span class="math display">\[
\begin{aligned}
P(\text{claim}|A\,\mathbf{and}\, B) &amp;\sim P(A\,\mathbf{and}\, B|\text{claim}) \\
&amp;=P(A|\text{claim})P(B|A,\text{claim})
\end{aligned}
\]</span> The key part is <span class="math inline">\(P(B|A,\text{claim})\)</span> – how likely is the testimony from <span class="math inline">\(B\)</span> given the testimony from <span class="math inline">\(A\)</span>? If it is independent, then one gains relevant information from the testimony. If <span class="math inline">\(B\)</span> is parroting <span class="math inline">\(A\)</span>, then this term is nearly <span class="math inline">\(1\)</span> and you will effectively only have <span class="math inline">\(P(A|\text{claim})\)</span>. If <span class="math inline">\(B\)</span> typically avoids agreeing with <span class="math inline">\(A\)</span>, and has heard <span class="math inline">\(A\)</span> giving the testimony, then the probabilities are shifted in the opposite direction. One can see that it becomes critical to know whether the parts of the process that provided your evidence are all independent.</p>
<p>Scientists design experiments to make sure that the evidence is as informative as it can be – that two measurements of the same thing giving the same answer are doing so not because they correlate but because they independently came to the same answer so we can be confident in it.</p>
</section>
<section id="lessons-from-probability" class="level2">
<h2 class="anchored" data-anchor-id="lessons-from-probability">Lessons from probability</h2>
<p>The mathematics of probability theory is the gold standard for all statistical inference. It structures all inference in a systematic fashion. However, it can be used without doing any calculations, as a guide to qualitative inference. Some of the lessons that are consequences of probability theory are listed here, and will be noted throughout this text in various examples.</p>
<ul>
<li>Confidence in a claim should scale with the evidence for that claim - the more evidence the higher confidence.</li>
<li>Ockham’s razor, which is the philosophical idea that simpler theories are preferred, is a consequence of Bayes’ Rule when comparing models of differing complexity that explain the data equally.</li>
<li>A complex model must explain the data <em>even better</em> than a simple model to be preferred.</li>
<li>Simpler means <em>fewer adjustable parameters</em> not fewer parameters or parts.</li>
<li>Simpler also means that the predictions are both <em>specific</em> and not <em>overly plastic</em>. For example, a hypothesis that is consistent with the observed data, but can also be consistent if the data were the opposite, would be overly plastic.</li>
<li>Your inference is only as good as the hypotheses (i.e.&nbsp;models) that you consider.</li>
<li>Extraordinary claims require extraordinary evidence. <span class="citation" data-cites="sagandemon">[@sagandemon]</span></li>
<li>It is better to explicitly display your assumptions rather than implicitly hold them.</li>
<li>It is a <em>good thing</em> to update your beliefs when you receive new information.</li>
<li>Not all uncertainties are the same.</li>
</ul>
<p>There is not a universal agreement for the translation of numerical probability values to qualitative terms in English (i.e.&nbsp;highly unlikely, somewhat unlikely, etc…). One rough guide is shown in <a href="#table-1">Table 1</a>. I will be following this convention throughout the book, but realize that the specific probability distinctions are a bit arbitrary.</p>
<section id="table-1" class="level4">
<h4 class="anchored" data-anchor-id="table-1">Table 1</h4>
<table class="table">
<caption>Rough guide for the conversion of qualitative labels to probability values.</caption>
<thead>
<tr class="header">
<th style="text-align: center;">term</th>
<th style="text-align: center;">probability</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">virtually impossible</td>
<td style="text-align: center;">1/1,000,000</td>
</tr>
<tr class="even">
<td style="text-align: center;">extremely unlikely</td>
<td style="text-align: center;">0.01 (i.e.&nbsp;1/100)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">very unlikely</td>
<td style="text-align: center;">0.05 (i.e.&nbsp;1/20)</td>
</tr>
<tr class="even">
<td style="text-align: center;">unlikely</td>
<td style="text-align: center;">0.2 (i.e.&nbsp;1/5)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">slightly unlikely</td>
<td style="text-align: center;">0.4 (i.e.&nbsp;2/5)</td>
</tr>
<tr class="even">
<td style="text-align: center;">even odds</td>
<td style="text-align: center;">0.5 (i.e.&nbsp;50-50)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">slightly likely</td>
<td style="text-align: center;">0.6 (i.e.&nbsp;3/5)</td>
</tr>
<tr class="even">
<td style="text-align: center;">likely</td>
<td style="text-align: center;">0.8 (i.e.&nbsp;4/5)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">very likely</td>
<td style="text-align: center;">0.95 (i.e.&nbsp;19/20)</td>
</tr>
<tr class="even">
<td style="text-align: center;">extremely likely</td>
<td style="text-align: center;">0.99 (i.e.&nbsp;99/100)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">virtually certain</td>
<td style="text-align: center;">999,999/1,000,000</td>
</tr>
</tbody>
</table>
</section>
</section>
</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>We use the symbol “<span class="math inline">\(\equiv\)</span>” to denote a <em>definition</em>, not just the equality relationship denoted by the “=”.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>this may be partly due to English being sloppier than math. In choices like the Linda problem, there may be an implied “and is <em>not</em> a feminist” in option (1) in common usage but is not strictly present<span class="citation" data-cites="Blais:2014aa">[@Blais:2014aa]</span>.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>It is important to recognize that the relationshop here is not causal but <em>logical</em>. Knowing that you drew a black card on the second card will change the probability you’d assign to drawing a black card on the first, even though they are not causally related.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>not all cases will lead to equal probabilities of the outcomes, because we almost always have <em>some</em> knowledge to go on. See the psychic octopus example in <span class="citation" data-cites="Blais:2014aa">[@Blais:2014aa]</span> for a specific case of this.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>The reader might be thinking at this time, “why do we have to do all this? Seems complicated!” I address this shortly, so please bear with me.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>In mathematical models, this is often referred to as having an <em>adjustable parameter</em><a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>Once we have the numerators, we can add them up to get the shared term <span class="math inline">\(P(3\spadesuit,4\spadesuit)\)</span><a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>In this way, knowledge is a subset of belief.<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p>An example of someone who should know better is Richard Carrier in his <a href="http://www.youtube.com/watch?v=YLvWz9GQ3PQ">“Is Philosophy Stupid” talk</a>., his <a href="http://www.amazon.com/Proving-History-Bayess-Theorem-Historical/dp/1616145595">books</a>, and his <a href="http://infidels.org/library/modern/richard_carrier/theory.html">articles</a>.<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>