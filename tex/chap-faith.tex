\chapter{Faith: A Matter of Definitions}\label{ch:faith}
%!TEX root = main.tex

The word {\em faith} has many definitions, some which seem conflicting.  However, as it is commonly used, the definitions point to a single quantity.  It is easiest to see this in the exploration of faith from specific examples.

\section{Introduction to Faith and Probability}

\subsection{Statements about Faith}

It may be helpful to start with the dictionary definition, and then follow with a number of statements about {\em faith} to see where the common usages fall.

\bi
\i faith (noun)\cite{MerriamWebster2009}
    \bi
    \i strong belief or trust in someone or something
    \i belief in the existence of God
    \i strong religious feelings or beliefs
    \i a system of religious beliefs
    \ei
\i Now faith is confidence in what we hope for and assurance about what we do not see. \footnote{Hebrews 11:1, New International Version}
\i Faith is trusting in, holding to, and acting on what one has
good reason to believe is true in the face of difficulties. The
difficulties may be where you have to take an action where the outcome
is beyond your control. (Tim McGrew)\cite{Brierley:2014aa}
\i Belief without evidence.  Pretending to know things you do not know. (Peter Boghossian)\cite{Brierley:2014aa}
\i One of the things that becomes apparent in serious Christian literature is that no one uses 'faith' in the sense of {\em believing things without reasons}. That might be Richard Dawkins' preferred definition - except when he was publicly asked by Oxford's Professor John Lennox whether he had 'faith' in his lovely wife - but it is important to know that in theology 'faith' always means {\em personal trust} in the God whose existence one accepts on other grounds. I think God is real for philosophical, historical, and experiential reasons. Only on the basis of my reasoned conviction can I then {\em trust} God - have faith in him - in the sense meant in theology.[http://mobile.abc.net.au/news/2014-04-18/dickson-tips-for-atheists/5397892][empasis in original]
\i Faith is the excuse people give when they believe something and don't have a good reason. When you believe something and have a good reason, then you give the reason. And in every other instance, you offer something that is faith. - Matt Dillahunty
\ei

From these few definitions, we can already see a few things.  First, people use the term in different ways, at different times, so it will be critical that we tack down a particular definition.  It is also critical to recognize which definition someone is using, so we don't inadvertently straw-man their argument.  Second, the two primary components that seem to make up all definitions of faith are {\em belief} and {\em trust}.  Faith seems to not be a synonym of either, but a particular combination of them with some restrictions - not all beliefs or acts of trust require faith.

\subsection{Belief, Trust, and Faith}

We have already seen that {\em belief} is represented mathematically by {\em probability}, so where {\em faith} requires belief we will employ probabilities.  {\em Trust}\cite{MerriamWebster2009} is ``belief that someone or something is reliable, good, honest, effective, etc.'' So it would seem that trust is a subset of belief, like knowledge is a subset, pertaining specifically to the reliability or goodness of the thing believed. 

Faith, however, seems to go a bit further than trust and involve {\em action} or the willingness to act.  When asked by Peter Boghossian, {\em ``why don't we say that we have faith in the existence of chickens?''}, Tim McGrew replies, 
\pquote{We are venturing nothing on the existence of chickens. When I believe
that chickens exist and I act on that belief I am not taking any step
that places outcomes I care about beyond my direct control. [In the
case of religion], people are placing the outcome of their eternal
soul out of their control. They are taking a risk where the outcomes
matter. The decision itself is evidenced but the outcome is
uncertain.}

\subsection{Utility - Probability and Action}

Probability relates to belief, a measure of state of knowledge about a claim or set of claims.  We can use the mathematics of probability to determine the most likely claim, and use it to inform our actions, but it isn't enough to truly determine the best course of action.  For that, we need to extend the mathematics to include the notion of {\em utility}, an extension commonly referred to as {\em decision theory}.  Because faith seems to involve action or potential actions, it to will need to be formulated in this way.  

Decision theory uses the idea of expected value to aid in making decisions, defined as\cite{Wikipedia:2015aa}
\begin{quote}
The idea of expected value is that, when faced with a number of actions, each of which could give rise to more than one possible outcome with different probabilities, the rational procedure is to identify all
possible outcomes, determine their values (positive or negative) and the
probabilities that will result from each course of action, and multiply
the two to give an expected value. The action to be chosen should be the
one that gives rise to the highest total expected value.
\end{quote}

The utility values, costs and benefits, could be written in monetary terms, but need not.  One needs only to have a scale to represent how good or bad an outcome is.  The total expected value, also called the  average utility, is just the sum of the individual costs and benefits associated with possible outcomes, weighted by their probability - more likely outcomes are weighted more than less likely ones.  An example will help.

The example here is called the "farmer's dilemma"\cite{jordaan2005decisions}, concerns a farmer who can plant one of three crops (labeled $A, B, $ and $C$) with the possibility of three different environments out of the farmer's control, {\em perfect weather}, {\em fair weather}, and {\em bad weather}.  Each of the three crops fare differently in different weather, and thus provide different costs and benefits to the farmer depending on the environment.  Crop $A$, for example, does very well in good weather but very badly in bad, whereas crop $C$ doesn't do as well but is more consistent, with crop $B$ in between.  This can be summarized by the following table of utilities showing benefits (positive) and costs (negative) for each possible combination:

\begin{tabular}{@{}llll@{}}
\toprule
 & \multicolumn{3}{c}{\textbf{Utility (benefits and costs)}}   \\ \midrule
 & \textit{perfect weather} & \textit{fair weather} & \textit{bad weather}   \\
\textit{plant crop $A$} & 11 & 1 & -3  \\
\textit{plant crop $B$} & 7 & 5 & 0  \\
\textit{plant crop $C$} & 2 & 2 & 2   \\ \bottomrule
\end{tabular}
\vspace{.1in}

Any decision the farmer makes must include the probabilities (his state of knowledge) of the weather environments.  At the extremes, it is easy to see this.  If perfect weather is nearly guaranteed, for example, then planting crop $A$ is of course the best option, whereas if bad weather is guaranteed, then planting crop $C$ is the best.  How does one handle the decision away from the extremes?  This is done by asking, what is the average utility (benefit or cost) for each action, and then choosing the action which maximizes this.  Imagine that the farmer consults a meteorologist, and they determine the following probabilities for the weather environment\marginnote{It is possible in some cases that the environmental state also depends on the actions taken.  This is easy to add to this framework, but makes this particular example needlessly complex.}
\beqn
\P{perfect weather}&=&0.1 \\
\P{fair weather}&=&0.5 \\
\P{bad weather}&=&0.4 \\
\eeqn

The average utility\marginnote{Average, or expected, value of a variable $U$ is denoted with angle brackets, $\langle U \rangle$} for each action is simply the sum of the probabilities of each environment times the utility for that environment given the action, such as
\beqn
\langle U_A \rangle &=& \P{perfect weather}\times {\rm U}(\mbox{perfect weather}|\mbox{plant crop $A$}) + \\
&& \P{fair weather}\times {\rm U}(\mbox{fair weather}|\mbox{plant crop $A$}) + \\
&& \P{fair weather}\times {\rm U}(\mbox{bad weather}|\mbox{plant crop $A$}) \\
&=& 0.1 \times 11 + 0.5 \times 1 + 0.4\times (-3) = 0.4
\eeqn
Performing the same calculation for all of the actions yields,
\beqn
\langle U_A \rangle &=& 0.1 \times 11 + 0.5 \times 1 + 0.4\times (-3) = 0.4 \\
\langle U_B \rangle &=& 0.1 \times 7 + 0.5 \times 5 + 0.4\times 0 = 3.2 \\
\langle U_C \rangle &=& 0.1 \times 2 + 0.5 \times 2 + 0.4\times 2 = 2.0
\eeqn

and the best action would be planting crop $B$, because it has the highest expected utility.

The primary point about this process that is relevant to our discussion of faith is that the process involves two separate entities - the probability of various states and the value those states are to us given our actions.  This maps directly to the concepts of {\em belief} and {\em trust}, respectively.  One can focus on each one individually, but it is the combination that is important.  

Although there are cases where the average utility is a bad guide, it is a very useful framework to structure a problem.  It should be noted that {\em utility} does not need to be restricted to money, but can include things like comfort and discomfort.  For example, someone could be {\em risk averse}, which means that they put a utility on some psychological comfort at the expense of some monetary loss.  Thus the utility value would combine both.  

\section{Rollercoasters: Faith in Everyday Life}

Words have meaning, and if we are going to communicate with each other
we need to make sure to use words as carefully as we can.  Otherwise,
misunderstandings abound.  It seems very common that a word like
``faith'' is used by different people for different ends, and the
definition shifts even within an argument.  Take for example, the video by Rich Spear\cite{Spear:2013aa}.  In it, Spear presents a distinction drawn between ``faith'' and ``belief'', using an analogy of a roller-coaster - belief in the ride being safe vs trusting it being safe enough to ride on.  Notice that his focus is on trust, and thus on {\em action}.  

It is clear that one must {\em at least} believe the ride is safe as a prerequisite for trusting it. Since when we say we believe \emph{strongly} in a proposition $A$ when $P(A)>0.95$ (or some other, somewhat arbitrary, high number), we can map this prerequisite to something like the following
\beqn
\P{safe} = 0.99 \\
\P{unsafe} = 0.01
\eeqn

Once you believe it is safe, do you trust it to ride?  This brings in decision theory, where we mix probabilities with utility measures. You could believe it to be safe at the $\P{safe} = 0.99$ level, but still not trust it ``with your life'' because of the \emph{cost} associated with being wrong.  A utility table might look like

\begin{tabular}{@{}lll@{}}
\toprule
 & \multicolumn{2}{c}{\textbf{Utility (benefits and costs)}}  \\ \midrule
 & \textit{safe} & \textit{unsafe}\\
\textit{ride} & 10 & -1000   \\
\textit{don't ride} & 0 & 0  \\ \bottomrule
\end{tabular}
\vspace{.1in}

Calculating the average utility for each action we get
\beqn
\langle U_{\mbox{ride}}\rangle &=& 0.99 \times 10 + 0.01\times (-1000) = -0.1 \\
\langle U_{\mbox{don't ride}}\rangle &=& 0.99 \times 0 + 0.01\times 0 = 0 
\eeqn
so it is better not to ride.

As a result, {\em trust} requires both belief and a sufficiently positive net utility. Placed in these terms it is much more clear how the argument is set up.

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  when the Spear says that ``faith'' is like ``trust'', he is
  already approaching the problem with strong belief, and is assessing
  utility - and he rightly claims that belief is not enough.
\item
  when the atheists say that ``faith'' is ``belief without evidence'',
  they are addressing the strength of the evidence to obtain strong
  belief in the first place - and claiming that the evidence is not sufficient.
\item
  when the Spear and others say that ``faith is rational'' they are either talking about utility, not belief, or they are claiming that the
  evidence is in fact good enough for strong belief, and then
  consequently high utility.
\end{itemize}

In all cases, it seems as if for the religious, utility and belief are
muddled when using the word ``faith''.  For the atheist, ``faith'' is
always first and foremost about belief, because even the usage involving trust has belief as a prerequisite.  Perhaps if we frame the problem in terms of belief (probability) and utility we can clear up the fog surrounding discussions of the term {\em faith}.

\section{Faith and Trust}

We see the same structure occurring in an ``{\em Unbelievable}'' podcast\cite{Brierley:2014aa} between theist Tim McGrew and  Peter Boghossian.  Because they were not thinking in terms of the framework presented here, they talked past each other through most of the episode.  In this discussion, Boghossian insists that faith is ``belief without evidence'' or ``pretending
to know things you do not know'', and Tim McGrew insists that faith is more like trust.  The discussion then devolved into a back and forth with both sides claiming that ``all the people I know use my definition'', and was generally unproductive.  It is clear, however, that in the expected utility equation,
\beqn
\langle U_{\mbox{action $A$}} \rangle &=& \P{outcome 1}\times U(\mbox{outcome 1}|\mbox{action $A$}) + \\
&&\P{outcome 2}\times U(\mbox{outcome 2}|\mbox{action $A$}) + \\
&&\vdots
\eeqn
Boghossian is focusing on the probabilities ($\P{outcome 1}$, $\P{outcome 2}$, etc...) and McGrew is focussing on the utilities ($U(\mbox{outcome 1}|\mbox{action $A$})$, $U(\mbox{outcome 2}|\mbox{action $A$})$, etc...)  

\subsection{The Discussion}

McGrew says that very few Christians (less than 1\%) would use Boghossian's definition of faith, ``pretending to know things you do not know''.  We agree that no Christian would \emph{articulate} this definition of
faith, however they may be \emph{functionally} using it, which we will
address later.

McGrew opens with 
\pquote{Faith is trusting in, holding to, and acting on what one has
good reason to believe is true in the face of difficulties. The
difficulties may be where you have to take an action where the outcome
is beyond your control.}

The example he gives is jumping out of an airplane, where one has
faith in ones instructor to have packed your parachute properly. Ones
act of jumping draws the distinction between faith and {\em hope} (if you just {\em hoped} your instructor packed it, you wouldn't jump), and the decision is made in the face of evidence, not despite it or without it.

Boghossian's general strategy is to ask a series of questions, to try to highlight the critical points.  For example, we get the following exchange:
\bi
\i Boghossian: {\em ``what do people mean when they accuse someone of having
`faith in evolution' ''}?
\i McGrew: {\em ``You're trusting in something that you cannot completely verify because it doesn't lie open to your senses.''}
\i Boghossian: {\em ``what do people mean when they say `I don't have enough
faith to be an atheist' ''}?
\i McGrew: {\em ``They have belief in something in the face of certain difficulties, where the weight of the difficulties is greater on one side compared to the other.''}
\i Boghossian: {\em ``Why don't we say that we have faith in the
existence of chickens?''}
\i McGrew:  {\em ``We are venturing nothing on the existence of chickens. When I believe that chickens exist and I act on that belief I am not taking any step that places outcomes I care about beyond my direct control. [In the case of religion], people are placing the outcome of their eternal soul out of their control. They are taking a risk where the outcomes matter. The decision itself is evidenced but the outcome is
uncertain.''}
\i Boghossian: {\em ``Do you have faith or evidence that Islam is
false?''}
\i McGrew: {\em ``Why would I use the word `faith' when I am venturing nothing on Islam?
I am a little bit confused about the framing of the question that way. I
think I have evidence that it is false, but since I am not venturing on
Islam, I'm not sure why the word faith would come in.''}
\ei


\subsection{Addressing the Definitions}\label{addressing-the-definitions}

Clearly claims using expected utility require that probability
assignments have already been made, so claims of utility must
necessarily be probability claims as well. When translated into these
more precise terms, both McGrew's and Boghossian's claims begin to make more
sense. It will also show that McGrew is in fact using the Boghossian's definition, in
some cases even while denying it.

\begin{quote}
You have faith that your instructor packed your parachute, as opposed to Peter packing it.  Your act of jumping makes faith more than simply hope (if you just hoped your instructor packed it, you wouldn't jump), and the decision is made in the face of evidence, not despite it or without
it.
\end{quote}

The equations are:
\beqn
\langle U_{\mbox{jump}}\rangle &=& \P{instructor packed}\times \Ug{instructor packed}{jump} + \\
&& \P{Peter packed}\times \Ug{Peter packed}{jump} \\
\langle U_{\mbox{don't jump}}\rangle &=& \P{instructor packed}\times \Ug{instructor packed}{don't jump} + \\
&& \P{Peter packed}\times \Ug{Peter packed}{don't jump}
\eeqn
with a possible utility table

\begin{tabular}{@{}lll@{}}
\toprule
 & \multicolumn{2}{c}{\textbf{Utility (benefits and costs)}}  \\ \midrule
 & \multicolumn{2}{c}{{\em Who packed the parachute?}}  \\ 
  & \textit{Instructor } & \textit{Peter}\\
\textit{jump} & 100 & -10000   \\
\textit{don't jump} & 0 & 0  \\ \bottomrule
\end{tabular}
\vspace{.1in}

For this analysis to work, we would have at least,
\bi
\i $\P{instructor packed} \sim 1$: one is nearly certain the instructor packed the parachute
\i $\P{Peter packed} \sim 0$: one is nearly certain that Peter {\em didn't} pack the parachute
\i $\Ug{instructor packed}{jump}\gg 1$: good benefit from jumping, with instructor packing the  parachute
\i $\Ug{Peter packed}{jump}\ll 0$: large cost  from jumping, with Peter packing the  parachute
\i $\Ug{Peter packed}{don't jump}=\Ug{instructor packed}{don't jump}\sim 0$: neutral gain for not jumping in either case
\ei

\subsection{Analyzing the Responses}\label{sec:mcgrewresponse}

Notice, for McGrew to have ``faith in his instructor'', two things must be true:
\be
\i $\P{instructor packed} \sim 1$: one is nearly certain the instructor packed the parachute
\i $\Ug{instructor packed}{jump}\gg 1$: good benefit from jumping, with instructor packing the  parachute
\ee

McGrew wants to focus on point (2), while Boghossian wants to focus on point (1). Once seen this way, it is very easy to understand the responses.

For example, why don't we say that we have faith in the existence of
chickens? Because,
\beqn
\Ug{chickens exist}{action} \sim \Ug{chickens don't exist}{action}\sim 0
\eeqn
for all actions - we have nothing at stake, there is no utility, even if  we are confident that chickens exist (i.e. \(P(\mbox{chickens exist})\sim 1\)).

Does McGrew have have faith or evidence that Islam is false?  McGrew claims he has evidence that Islam is false, $\Pg{Islam}{data}\ll 1$, but is not venturing anything on Islam (or more accurately, on his choice to
not follow Islam), $\Ug{not-Islam}{action}\sim 0$. Again, Boghossian sees the first part (the probabilities), yet ignores the second part (the utilities).

Going back to the exchange, we note, however, that sometimes McGrew is also using Boghossian's definition:

\bi
\i Boghossian: {\em ``what do people mean when they accuse someone of having
`faith in evolution' ''}?
\i McGrew: {\em ``You're trusting in something that you cannot completely verify because it doesn't lie open to your senses.''}
\ei

Now I can think of no way to understand this statement from the
perspective of McGrew's definition:
\pquote{When I act on that belief I am taking some step that places outcomes I care about beyond my direct control.}

What outcomes are you placing beyond your control believing in
evolution? What obvious utility are you weighing in this case? As far as
we can see there is none, and so {\em faith} in this context is in fact being used here as ``belief without sufficient evidence''. 

\subsection{Priors and Faith}\label{priors-and-faith}

We think this brings in another aspect of faith, which we believe applies to all of the cases explored so far, and that is that faith is used only in contexts with low \emph{prior} probability. In this conversation,
they spoke of faith in the context of the supernatural, extreme
activities (i.e. jumping out of planes), events beyond our immediate
senses - all of which coincide with lower \emph{prior} probability, and
need \emph{more} evidence than is typical to overcome them. They may, or
may not, also have high utility. We don't have faith in the existence of
chickens because the existence of chickens has high \emph{prior}
probability.

Because of this, it makes sense that there are those who are not convinced by the evidence for things others have {\em faith} in, because of the necessary quantity and quality to bring a low {\em prior} probability up to a significant {\em posterior} probability.  For those who are convinced by the evidence, it also makes sense that they would then focus on the {\em utility} of the claims.  The problem that arises, however, is a problem with the word {\em faith}.  Since it is referring to two distinct components, the apologist can easily switch between them
without even noticing it themselves. Again, we put forward the suggestion to discuss things in terms of decision theory and avoid words with multiple meanings.  

\subsection{Without Evidence}

Although a bit shorter and punchier, the term ``belief without evidence'' is misleading, even if you know you are focussing on the probability side of the analysis.  The more honest phrase would be ``belief without \emph{sufficient} evidence''. When people say
there is no evidence for something (like God, UFOs, astrology, psychic
phenomena, etc\ldots{}), they really mean that there is terrible
evidence for something. Even in the case of something so poorly supported as astrology, there is \emph{some} evidence for its claims - the probability is not zero.  It may be very small, but one could imagine evidence in principle that would convince you, which means that the probability is indeed non-zero. The exaggerated, more
simple, phrase of ``belief without evidence'' is counterproductive,
especially when the more accurate phrase, ``belief without
\emph{sufficient} evidence'', is nearly as simple. 

\section{Does Science Have Faith?}

In his talk, ``Life: Creation or Evolution''\cite{Miller:2009aa}, Ken Miller makes the point that science should inform
faith and faith should inform science. He cites Paul Davies, a physicist
who has an interest in theism, and whose article
``Taking
Science on Faith''\cite{davies2007taking} takes the position that science itself is a
faith-based activity. Ken Miller points out, and one can confirm in Paul
Davies' article, that there are two tenets in science that are taken on
faith:

\begin{enumerate}
\item
  the universe is ultimately knowable and understandable
\item
  knowledge is better than ignorance
\end{enumerate}

These concepts, however, are fundamentally different than faith, or even axioms.  Even here, it is plain that the claims are referring to the {\em belief} part of faith, and not the {\em trust} part of faith.  The entire phrase ``taken on faith'' is a signal to the listener that this is so.


The first idea, that the universe is knowable, needs to be a bit more specific: what does it mean to be {\em knowable}? Prior to 1900, it was
believed that the pieces of a physical model, such as the force of
gravity, or the electric and magnetic fields of Maxwell were ``real'':
there was one-to-one correspondence between the model components and
things in the real world. Thus, it was believed, that knowing the model
you would know nature. After 1900, with the advent of quantum mechanics,
physical models were evaluated based on their predictive value: those
models that predicted well were good models. It was not believed that
there was necessarily a correspondence between the model components and
the real components in nature. Aspects of the model, such as the wave
function in quantum mechanics, were not believed to be real but simply useful in making
predictions. To know the world is to be able to predict what would
happen.

Let's say we replace ``understandable'' with ``predictable'', a
replacement which we think makes practical sense (how else would you
determine that you understand something?), and is directly in line with
modern physical thinking. Doing this, then tenet (1) ceases to be an
axiom, or something we take without sufficient evidence (``on faith''), but is observable. If the universe
is unpredictable, then all attempts at making prediction will fail. This
is not what we observe at all. Surely there are still things that are
unpredictable, such as the simultaneous value of the position and
momentum of the electron, or the positions of every molecule of air in
this room, but even there we can make specific predictions about average
quantities or the values of other variables of interest. Practically,
the universe has demonstrated itself to be understandable, on the whole.
This is not a matter of faith.

The second tenet (2) I would wager is too vague. What does ``better''
mean? Better for whom, or for what? Psychologically, one might argue
something akin to ``ignorance is bliss'', and there might be something
to that. If we define, however, ``better'' to be higher standard of
living (longer, healthier, more free life) then knowledge can be argued
to have a demonstrable benefit over ignorance. The results of science
has doubled the life expectancy in the past 100 years, and has allowed
us to live more free and healthy lives.  As Carl Sagan says, science delivers the
goods. Is there any convincing argument that ignorance is better, or
that we really can't decide which is better? 

There is a danger in using the word {\em faith} in these contexts.  It can communicate to the unaware that there are things that one should justifiably believe on insufficient evidence - a direct violation of the laws of probability.  It can also imply, for those who take {\em faith} to mean {\em trust}, that the scientists using the term are somehow admitting an agency in the universe that they don't intend.  It serves only to propagate sloppy thinking in both the fields of science and religion.

\section{Another Interaction - McGrath and Dawkins}

As part of the ``Root of All Evil'' program, Richard Dawkins conducted many interviews with theists.  One in particular, with theologian Alister McGrath, deals with the notion of faith\cite{Dawkins:aa}.  They start with a discussion about the term \emph{faith}, and McGrath
says

\pquote{
We're dealing with a different situation than, for example, evidence
that the moon orbits the earth at a certain distance
}

and

\pquote{
There are many possible ways of explaining {[}the world{]}, and we have
to make the very difficult judgement of which is the best of these
{[}explanations{]}\ldots{}evidence takes us thus far, but then when it
comes to deciding between a number of competing explanations, it is
extremely difficult to make an evidence-driven argument.
}

and

\pquote{
I believe faith is rational, in the sense that it tries to make the best
possible sense of things\ldots{}even though we believe this is the best
possible sense of things, we cannot \emph{prove} this is the
case\ldots{}there is a point where {[}faith{]} goes \emph{beyond} the
evidence
}

By this point, the reader should be able to tell that McGrath is employing the {\em belief} part of the expected utility form of {\em faith}.  One wonders in these cases why he doesn't simply talk about evidence, and the weight of
probabilities? Historians, for example, don't use the word \emph{faith}
even though they deal with probabilities, some of which are highly
uncertain. Scientists all the time deal with probabilities, without
invoking the word \emph{faith} in any paper.

Further, McGrath ignores the fact that there already is a proper and
rational method to address the ``decision between a number of competing
explanations'', that \emph{doesn't} go beyond the evidence, and doesn't
claim more knowledge than is justified. What is this method? It's called
the mathematics of probability! So, McGrath is claiming there is a
problem that faith solves, which is not a problem at all, and he is
using the word faith (at the moment) as synonymous with probability.

Why is he doing this? It seems as if it is because McGrath is holding to
a double standard, and shifts the definitions of concepts around
whenever pressed. He doesn't like the notion of believing strongly
without sufficient evidence (which, as we've seen, is one use of the word faith), so he
defines it (at the moment) to be equivalent to probabilities.

\subsection{Inference to the Best Explanation}

Then McGrath continues to talk about probabilistic reasoning,
and says that with faith one is doing \emph{inference to the best
explanation}, given a number of competing multiple explanations. As we
stated earlier, if all he means is that faith is probabilistic
reasoning, then we don't have an argument - except that we think he can make things more clear. We would contend, along with Dawkins, the \emph{vast} majority of people do not take it to mean this - even the notion of {\em faith} as {\em trust} isn't the same as this.

However, we'd like to challenge his basic premise: that in
dealing with multiple competing explanations that one should try to
``infer to the best explanation'', and \emph{believe strongly in that
explanation}. A simple example introduced in Section~\ref{sec:atheism_agnosticism} on page~\pageref{sec:atheism_agnosticism}, suffices to see this. In this example, we have two explanations of the number of stars, one which
says that there is an \emph{even} number of stars and another that says
that there is an \emph{odd} number of stars. Pretty much we know that,
at any given instant, one of these \emph{must} be true. However strong
belief in either one is completely unwarranted - there is simply no way
to know. From a probabilistic framework, we express this as

\begin{eqnarray*}
P({\rm odd}) &=&0.5 \\
P({\rm even})&=&0.5
\end{eqnarray*}

However, it is worse than that. Let's say we had a smidgen of evidence
toward the even-star model, such that we had:

\begin{eqnarray*}
P({\rm odd}) &=&0.499995 \\
P({\rm even})&=&0.500005
\end{eqnarray*}

Even though there is a \emph{best} explanation here (\emph{even} is
slightly more probable than \emph{odd}), and we have the exact
probabilities, it is \emph{still irrational} to hold strong belief in
either explanation. One really does have to look where the weight of the
probabilities lay. Inference to the best explanation fails as a guiding
principle in the face of uncertainty, and is not well defined in all
contexts. 

What is happening here is that on the face of it, ``inference to the best explanation'' sounds like a great thing - something we should always strive for.  However, when you look at what it {\em actually} means, it falls short unless you are in a situation where the best explanation is also very probable.  Strong belief is only justified when the claim is very probable, not just that is is the most probable amongst a number of (possibly nearly equivalent) alternatives.


\subsection{Shifting Sands}\label{playing-dodgeball-with-an-apologist}

One of the benefits of seeing these arguments in the light of the framework of probability is that it makes one sensitive to shifting definitions.  We saw that earlier in Section~\ref{sec:mcgrewresponse} where Tim McGrew changes his usage of the term {\em faith} depending on the response.  Here, McGrath does the same thing.

First it was ``faith is reasonable'', based on evidence, going beyond the evidence to the ``inference to the best explanation'' and that as a result one can have a reasonable faith in God.  Then, when asked about his belief in a creator, and the evidence for it,  despite having difficulty with the implied complexity of such a creator, he says

\pquote{
I want to go back to CS Lewis who says I believe in Christianity as I
believe the Sun has risen, not simply because I see \textbf{it} by
\textbf{by it} I see everything else. Belief in God gives you a way of
seeing the world that makes an awful lot of sense of it.
}

When pressed on what this implies, he says that 
\pquote{there are many
  reasons I believe in God and that {[}origins{]} is not even the
  primary one...religion really isn't much about where things came
  from, about things in the distant past, but really about how things
  are now. How to live your life, how to be moral, etc\ldots{}
  }
which then becomes 
\pquote{the key reason for believing God is Jesus, that
  there is something {[}in the Jesus story{]} that needs explanation.
}
and then, this becomes that it is not really about the life of Jesus, and his historicity, but how he was perceived by his followers - the significance they saw in the life and teaching of Jesus.

Notice how this keeps shifting? At first, it is about belief, and then it is about significance (which one could argue is a kind of utility).  Every time he gets pushed on the
specific consequences of his statement, he retreats, redefines, and
redirects the conversation.

He doesn't seem to realize that any explanation, even of things
currently, entails assumptions that can be tested - perhaps with
observations about the past. He can't simply say that religion is ``not
about where things came from'', when they explicitly make statements of
origins - statements which have been universally discredited. The
atonement, for example, \emph{does} depend critically on the existence
of Jesus, the existence the ``Fall'', and a creator of the universe -
for none of which did McGrath provide evidence. If Jesus didn't exist as
a real person (or even if he was just an ordinary guy) then it doesn't
matter that his followers simply \emph{believed} that Jesus was God
incarnate when determining ones belief in the doctrine of salvation. The
demonstration of the historicity of the events claimed is
\emph{necessary} for the doctrinal belief. If you don't have strong
evidence of the former, then you are not rational to believe strongly in
the latter - you'd be claiming to know things you could not know.

As a scientist, one takes an idea, and pushes the idea to it furthest
consequences to see where it breaks, or to see what it depends on.
McGrath seems to change the topic whenever this is done - he does not seem to want to
face the very real, specific consequences of his stated beliefs and
refuses to see the connections between the things that may be
confirmable (apparent design in the biology and the universe itself,
historicity of people and events, alleged miracle claims, etc\ldots{})
and the things that make him feel good, but are unmeasurable (existence
of heaven, the atonement of sins, etc\ldots{}).


\section{I don't have enough faith to be an atheist}

In their book {\em I don't have enough faith to be an atheist}\cite{geisler2004don}, Norman Geisler and Frank Turek are playing with the word {\em faith} to make a humorous title.  In their book, however, they too exhibit the dual-usage of the word {\bf faith} as in {\em belief} and as in {\em expected utility}.  

\todo{much more to do here}

\section{Pascal's Wager}

Blaise Pascal, a French philosopher, put forward an argument referred to now as ``Pascal's Wager''\cite{Wikipedia:2015ac} for the religious life .  The argument is based on decision theory, and is one of the first uses of this theory on any topic.  In the ``Wager'', Pascal states that people choose to believe or not believe in God, and the possible environments they find themselves in are the God either exists or doesn't.  He then sets up the utility table,

\begin{tabular}{@{}lll@{}}
\toprule
 & \multicolumn{2}{c}{\textbf{Utility (benefits and costs)}}  \\ \midrule
 & \textit{God Exists} & \textit{God Does Not Exist}\\
\textit{Believe in God} & $+\infty$ (infinite gain) & -1 (finite loss)   \\
\textit{Don't Believe in God} & $-\infty$ (infinite loss) & +1 (finite gain) \\ \bottomrule
\end{tabular}
\vspace{.1in}

It is clear then that the best course of action, given this utility table, is to believe.  There are many problems with this argument, some which impact the mathematics and others that are theological.  An example of the former is the analysis assumes only one possible God - what if you choose the wrong God?  Extending the table to include this would make the ``best choice'' not as clear cut.  An example of the latter is the idea that one cannot simple {\em choose} to believe, and the act of pretending to believe would go against the dictates of God.  

Pascal's Wager is, however, a useful starting point for a discussion and highlights some of the issues one faces when applying decision theory too simplistically. 

\section{A More Formal Exploration}

In the philosophical literature, there are more formal explorations of these concepts.  These explorations can be helped by casting the ideas into the probabilistic framework.  For example, Daniel Howard-Snyder considers what he calls ``Propositional Faith''\cite{howard2013propositional}.  He immediately recognizes, as we do here, that the word {\em faith} has many usages which he clears away as being not on topic, and focuses on the use of faith in a sentence like {\em ``A wife might have faith that her marriage will survive a crisis''} or {\em ``Frances has faith that her young songs will live long and fulfilling lives.''}  Each of these cases has the sentence structure of ``$A$ has {\em faith that} $B$''.  In his clearing of other uses, Howard-Snyder removes the following usages,
\bi
\i Faith as a noun (e.g. ``earnestly content for {\em the faith}'')
\i Faith as a process (e.g. the process of coming to believe the Gospel as a result of the Holy Spirit)
\i Taking something {\em on faith} (i.e. taking on authority or testimony)
\i Faith as assent to a proposition with certainty
\i Faith as a kind of knowledge
\ei

It is interesting to see what Howard-Snyder considers propositional faith, and some of the considerations around it.  We believe he is still using the term inconsistently, in two ways - one which matches the structure we've been exploring in this book, and the other as a direct synonym for {\em hope}.  Consider the following case from his paper.
\pquote{Propositional faith does not require `certainty', without any hesitation or hanging back.  A wife might have faith that her marriage will survive a crisis, while harboring doubts about it.  Indeed, propositional faith is precisely that attitude in virtue of which she might possess the inner stability and impetus that enables her to contribute to the realization of that state of affairs, despite her lack of certainty.}

This case matches decision theory quite nicely. The equations are:
\beqn
\langle U_{\mbox{action}}\rangle &=& \Pg{successful marriage}{action}\times \Ug{successful marriage}{action} + \\
&& \Pg{failed marriage}{action}\times \Ug{failed marriage}{action} \\
\langle U_{\mbox{inaction}}\rangle &=& \Pg{successful marriage}{inaction}\times \Ug{successful marriage}{inaction} + \\
&& \Pg{failed marriage}{inaction}\times \Ug{failed marriage}{inaction}
\eeqn
where the probabilities of the outcomes, as well as the utilities, clearly change with the the possible actions.  For example, we expect action to have a positive effect on the probability of a successful marriage, $\Pg{successful marriage}{action}>\Pg{successful marriage}{inaction}$.


A possible utility table, which reflects the idea that, if the marriage is successful without action then there was time and resources saved, but if the marriage failed without action there is a penalty in the form of guilt over lost opportunity.  Obviously there are many complications that this table overlooks, and should be seen as a basic approximation.

\vspace{.1in}
\begin{tabular}{@{}lll@{}}
\toprule
 & \multicolumn{2}{c}{\textbf{Utility (benefits and costs)}}  \\ \midrule
 & \multicolumn{2}{c}{{\em How is the marriage?}}  \\ 
  & \textit{successful marriage} & \textit{failed marriage}\\
\textit{action}  & 90 & -100   \\
\textit{inaction} &100 & -110  \\ \bottomrule
\end{tabular}
\vspace{.1in}

 The high positive utility that the wife puts on her successful marriage, and high negative utility to its failure, directs her to make actions in her marriage's favor despite having lower probability of its success.  This is the notion of {\em faith} worked out.

Another case is
\pquote{But one can have faith that something is thus-and-so without entrusting one's welfare to it in any way, as when I have faith that Emily will survive breast cancer but I do not entrust my well-being to her or her survival}
where as far as we can see, the use of {\em faith} here is completely indistinguishable from {\em hope}.  There is no utility explicit in the statement, and the probability is presumed to be low.  


