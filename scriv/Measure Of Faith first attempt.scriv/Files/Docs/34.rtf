{\rtf1\ansi\ansicpg1252\cocoartf1348\cocoasubrtf170
{\fonttbl\f0\fnil\fcharset0 Cochin;}
{\colortbl;\red255\green255\blue255;}
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\fi360\sl288\slmult1\pardirnatural

\f0\fs28 \cf0 ## <$Title>\
\
Clearly the terms belief, knowledge, and proof are related but it is the framework of probability that helps us be specific about their differences.  We can summarize the situation with the following,\
\
* *Belief* is measured by probability.  Higher probability is equivalent to stronger belief, and likewise, lower probability is equivalent to weaker belief.\
* *Knowledge* is a subset of belief, described more specifically below.\
* *Proof* refers specifically to the result of a *deductive* process.  In this process, one starts with some (given) axioms, and can demonstrate *with certainty* (i.e. prove) a number of theorems (i.e direct consequences) from those axioms.  Thus, the word proof should only be used in situations involving *certainty*, or in other words, probabilities of exactly 1 or exactly 0 only.\
\
### Belief\
\
>We say we believe a proposition $A$ when $P(A)>0.5$.  We say we\
>believe *strongly* in a proposition $A$ when $P(A)>0.95$\
>or some other, somewhat arbitrary, high number.  The strength of a\
>belief is a *scale* measured my the probability assigned to that proposition.\
\
Everything we have covered so far in this book relates to belief.\
\
### Knowledge\
\
What is knowledge?  Plato gave the following definition of knowledge:\
\
> Knowledge is justified true belief.[#fine2003plato]\
\
This is an unsatisfying definition because, it seems, in\
order to justifiably label anything as *knowledge* with this\
definition we'd need to be able to independently determine that the\
proposition is true. This presupposes that there is some \'93outside\'94\
knowledge, which we feel comes too close to assuming a religious\
justification at the outset.  We believe there is likely to be a truth to be known, but that we can never truly know what it is for certain - but this is not a problem. It is a red herring to bring up 100% certainty for knowledge, because it is never achievable, and isn't what we practically call knowledge[^knowledgebelief]. We prefer a definition inspired by Stephen J Gould:\
\
[^knowledgebelief]: In this way, knowledge is a subset of belief.\
\
>In science, \'91fact\'92 can only mean `confirmed to such a degree that it\
>would be perverse to withhold provisional assent.\'92 I suppose that apples\
>might start to rise tomorrow, but the possibility does not merit equal\
>time in physics classrooms.[#gould1981evolution]\
\
\
Where it says \'93fact\'94, read \'93knowledge\'94.  Where it says \'93science\'94\
read \'93life\'94.  The fact, or knowledge, that the Sun rises in the east and sets in \
the west is not due to a formal *proof* that this is always true, or will \
continue indefinitely into the future.  It is an admission that the probability is so \
outrageously high, given the evidence of every other sun rise and sun set observed, \
and the further confirmation of models of the solar system, that it would be \'93perverse to withhold provisional assent\'94.  We accept the claim as a practical matter, despite not being 100\\% certain, because of the overwhelming probabilities.  This we call knowledge.  It is thus never a problem to admit lack of certainty in knowledge, and it can be seen as an obvious diversion if anyone tries to argue in a manner that suggests it's a problem.\
\
Mathematically, we might write[^approxnotation] it as $P(A)>0.9999 \\approx 1$.  Notice that we don't need 100% certainty to claim knowledge, and that it is possible for the \'93knowledge\'94 to be wrong (although, by definition, it is highly unlikely for this to be the case).  \
\
[^approxnotation]: $P(A)\\approx 1$ means that the probability of $A$ is *approximately* equal to 1\
\
We can ask the question, how did we come to this knowledge?  The answer is simply, by applying the rules of probability!  According to Bayes' rule, we update our probabilities given the evidence.  This can lead us to approach, but never equal, probability of 1.  We can approach, but never achieve, complete certainty of any claim.  Rationality only insists that we apply the rules of probability systematically. \
\
### Proof\
\
Do *proof* and *evidence* mean the same thing?  No, they don't. To summarize, proof refers specifically to the result of a *deductive* process.  In this process, one starts with some (given) axioms, and can demonstrate *with certainty* (i.e. prove) a number of theorems (i.e direct consequences) from those axioms.  Thus, the word proof should only be used in situations involving *certainty*, or in other words, probabilities of exactly 1 or exactly 0 only.\
\
Evidence, however, factors into inference through an *inductive* process, not *deductive*.  Induction is just another name for the application of the rules of probability, so we have been doing that from the beginning of the book.  Deduction is just another name for formal logic, where the probabilities are restricted to values of 0 or 1 only.  As a result, we have the following maxim,\
\
\
> *Proof* does not exist in science, only in math and philosophy.\
\
The only place you can have proof is where you have *axioms*\
(i.e. unprovable assertions), and can then *prove* a number of\
consequences of those axioms. We can prove, for example, that the sum of\
the angles of a triangle is 180 degrees, if we start with the Euclidean\
axioms of geometry. Science doesn't have axioms, and thus there are no\
proofs - there is only evidence. We sometimes hear the term \'93proven\
scientifically\'94, even from people who should know better\\footnote\{An example of someone who should know better is Richard\
Carrier in his [\'93Is Philosophy Stupid\'94 talk]({\field{\*\fldinst{HYPERLINK "http://www.youtube.com/watch?v=YLvWz9GQ3PQ"}}{\fldrslt http://www.youtube.com/watch?v=YLvWz9GQ3PQ}}), his [books]({\field{\*\fldinst{HYPERLINK "http://www.amazon.com/Proving-History-Bayess-Theorem-Historical/dp/1616145595"}}{\fldrslt http://www.amazon.com/Proving-History-Bayess-Theorem-Historical/dp/1616145595}})\
and his [articles]({\field{\*\fldinst{HYPERLINK "http://infidels.org/library/modern/richard_carrier/theory.html"}}{\fldrslt http://infidels.org/library/modern/richard_carrier/theory.html}}).\
\
Another way of putting it is that probability theory contains deductive logic as a special case.  As it applies to science, it has the following consequence\
\
> All of the evidence in the universe cannot bring the probability of a scientific claim to certainty.\
\
To see this directly, imagine we have two (and only two) hypotheses for\
the Earth - flat earth and round earth. We can write Bayes' rule for the\
probability of each given the data. Note that this data includes things\
like the experience of airplane flight, Magellan's trip, pictures from\
space - all of which could be faked! The flat earth hypothesis is not\
*logically* impossible, it's just been overwhelmed by the evidence.\
\
<!--\
\\begin\{eqnarray*\}\
P(\{\\rm round\}|\{\\rm data\}) &=& \\frac\{P(\{\\rm data\}|\{\\rm round\})P(\{\\rm round\})\}\{P(\{\\rm data\}|\{\\rm flat\})P(\{\\rm flat\})+P(\{\\rm data\}|\{\\rm round\})P(\{\\rm round\})\}\\\\\\\\\
P(\{\\rm flat\}|\{\\rm data\}) &=& \\frac\{P(\{\\rm data\}|\{\\rm flat\})P(\{\\rm flat\})\}\{P(\{\\rm data\}|\{\\rm flat\})P(\{\\rm flat\})+P(\{\\rm data\}|\{\\rm round\})P(\{\\rm round\})\} \
\\end\{eqnarray*\}\
-->\
\
Notice that, no matter how well the round earth hypothesis explains the\
data, $$P(\{\\rm data\}|\{\\rm round\})\\approx 1$$ and how unlikely you\
believe it is that the Earth is flat even *before* the data,\
$$P(\{\\rm flat\})\\ll 1$$ as long as there is some *possible* (even if\
seriously contrived) way to explain the data with the flat earth\
hypothesis, $$P(\{\\rm data\}|\{\\rm flat\}) \\neq 0$$ it is\
*mathematically impossible* to make the round earth hypothesis\
certain, $$P(\{\\rm round\}|\{\\rm data\})< 1$$\
\
On the right-hand side of Bayes' Rule, the closer the round-earth terms\
and the flat-earth terms get to 1 and 0, respectively, the closer the\
left-hand terms get to 1 and 0, but they never *equal* 1 and 0.\
This does not mean that we can't be *confident* of claims, only\
that we cannot have *absolute certainty of anything* in science\
(and therefore, in life in general). Anyone who doesn't understand that\
does not understand science.\
\
For it to be *reasonable to believe in something*, it must rise to a level of probability that you would label it as *belief*.  Does this ever happen, or should this ever happen, with untrue things?  Certainly.  Here are a few that come to mind.\
\
1. the world is flat - as long as you are constrained to not live near the shore, or see a lunar eclipse\
2. life is designed - before the advent of Darwin's theory of natural selection\
3. the Sun, and the stars, all go around the Earth - until the advent of physics\
\
In each of these cases there is in fact strong evidence for the claims, and against the counter claims, to make it reasonable to believe them (at the time).  It is no longer reasonable to believe these claims - the process of reason forces one to adjust the probabilities of the hypotheses given new evidence, and to discard those hypotheses that become too improbable.\
\
\
}